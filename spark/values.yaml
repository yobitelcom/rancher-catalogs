 # Default values for spark.
# This is a YAML-formatted file.
# Declare name/value pairs to be passed into your templates.

#namespace: spark
Spark:
  Path: "/spark"

Master:
  Name: master
  Image: "yobitel/spark"
  ImageTag: "2.4.5"
  Replicas: 1
  Component: "spark-master"
  Cpu: "100m"
  Memory: "512Mi"
  ServicePort: 7077
  ContainerPort: 7077
  # Set Master JVM memory. Default 1g
  # DaemonMemory: 1g
  ServiceType: LoadBalancer
  
WebUi:
  Name: webui
  ServicePort: 8080
  ContainerPort: 8080

Worker:
  Name: worker
  Image: "yobitel/spark"
  ImageTag: "2.4.5"
  Replicas: 3
  Component: "spark-worker"
  Cpu: "100m"
  Memory: "512Mi"
  ContainerPort: 8081
  # Set Worker JVM memory. Default 1g
  # DaemonMemory: 1g
  # Set how much total memory workers have to give executors
  # ExecutorMemory: 1g
  Autoscaling:
    Enabled: true
  ReplicasMax: 10
  CpuTargetPercentage: 80
  MemoryTargetPercentage: 80

livenessProbe:
  enabled: true
  httpGet:
    path: /api/health
    port: 8080
  failureThreshold: 3
  initialDelaySeconds: 0
  periodSeconds: 10
  successThreshold: 1
  timeoutSeconds: 1

readinessProbe:
  enabled: true
  httpGet:
    path: /api/health
    port: 8080
  failureThreshold: 3
  initialDelaySeconds: 0
  periodSeconds: 10
  successThreshold: 1
  timeoutSeconds: 1


Zeppelin:
  Name: zeppelin
  Image: "apache/zeppelin"
  ImageTag: "0.8.2"
  Replicas: 1
  Component: "zeppelin"
  Cpu: "100m"
  ServicePort: 8080
  ContainerPort: 8080
  ServiceType: LoadBalancer
  Ingress:
    Enabled: false
    Path: "/"
    Tls: []
  #    - Hosts:
  #    SecretName: zeppelin
  # Used to create an Ingress record.
  # Hosts:
  # - example.local
  # Annotations:
  #   kubernetes.io/ingress.class: nginx
  #   kubernetes.io/tls-acme: "true"
  # Tls:
  #   Enabled: true
  # Secrets must be manually created in the namespace.
  #   SecretName: example-tls
  #   Hosts:
  #   - example.local
  Persistence:
    Config:
      Enabled: false
      ## etcd data Persistent Volume Storage Class
      ## If defined, storageClassName: <storageClass>
      ## If set to "-", storageClassName: "", which disables dynamic provisioning
      ## If undefined (the default) or set to null, no storageClassName spec is
      ## set, choosing the default provisioner. (gp2 on AWS, standard on
      ## GKE, AWS & OpenStack)
      StorageClass: "standard"
      ## Set default PVC size
      Size: 30Gi
      ## Set default PVC access mode: https://kubernetes.io/docs/concepts/storage/persistent-volumes/#access-modes
      AccessMode: ReadWriteOnce

backup:
  # Backup must use RBAC
  # So by enabling backup you are enabling RBAC specific for backup
  #name: spark
  enabled: true
  # Used for label app.kubernetes.io/component
  componentName: "backup"
  # Schedule to run jobs. Must be in cron time format
  # Ref: https://crontab.guru/
  schedule: "*/5 * * * *"
  annotations:
    # Example for authorization to AWS S3 using kube2iam
    # Can also be done using environment variables
    iam.amazonaws.com/role: "spark"
  image:
    repository: "maorfr/kube-tasks"
    tag: "0.2.0"
  # Additional arguments for kube-tasks
  # Ref: https://github.com/maorfr/kube-tasks#simple-backup
  extraArgs: []
  # Add existingSecret for AWS credentials
  existingSecret: {}
  ## Example for using an existing secret
   # sparkaws:
  ## Use this key for AWS access key ID
     # awsaccesskey: spark_aws_access_key
  ## Use this key for AWS secret access key
     # awssecretkey: spark_aws_secret_key
  # Add additional environment variables
  env:
  # Example environment variable required for AWS credentials chain
  - name: "AWS_REGION"
    value: "us-east-1"
  resources:
    requests:
      memory: 1Gi
      cpu: 1
    limits:
      memory: 1Gi
      cpu: 1
  # Destination to store the backup artifacts
  # Supported cloud storage services: AWS S3, Minio S3, Azure Blob Storage, Google Cloud Storage
  # Additional support can added. Visit this repository for details
  # Ref: https://github.com/maorfr/skbn
  destination: "s3://spark-data/backup"
checkDeprecation: true






    

